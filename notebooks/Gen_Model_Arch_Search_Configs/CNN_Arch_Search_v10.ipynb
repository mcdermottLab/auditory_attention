{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/imgriff/conda_envs/torch_11_cuda_11_pitch/lib/python3.9/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import sklearn as sk\n",
    "# from skopt import gp_minimize, forest_minimize\n",
    "from src.layers import padding as pad_utils\n",
    "from src.spatial_attn_lightning import BinauralAttentionModule\n",
    "import yaml "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second pass architecture search using v10 dataset (final version)\n",
    "\n",
    "This will use the 7 good architectures idetified in the first pass architecture search, and include 2 more to have 10 total models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Track good architecutres \n",
    "good_arch_config_names = ['word_task_v09_4MGB_ln_first_arch_1',\n",
    "                        'word_task_v09_4MGB_ln_first_arch_2',\n",
    "                        'word_task_v09_4MGB_ln_first_arch_4',\n",
    "                        'word_task_v09_4MGB_ln_first_arch_6',\n",
    "                        'word_task_v09_4MGB_ln_first_arch_7',\n",
    "                        'word_task_v09_4MGB_ln_first_arch_8',\n",
    "                        'word_task_v09_4MGB_ln_first_arch_9']\n",
    "len(good_arch_config_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly generate architectures\n",
    "\n",
    "### Required conditions:\n",
    "* N parameters < 200M\n",
    "* 4 < N layers < 11\n",
    "* 2 < output height < 8\n",
    "* 2 < output width < 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write configs \n",
    "\n",
    "from pathlib import Path\n",
    "import yaml \n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "## import default config \n",
    "outdir = Path(\"config/arch_search\")\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "base_config = yaml.load(open(\"config/binaural_attn/word_task_v10_main_feature_gain_config.yaml\", 'r'), Loader=yaml.FullLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_height: 8, output_len: 5, n layers: 9, our total_params: 58.18M\n",
      "output_height: 8, output_len: 3, n layers: 10, our total_params: 76.67M\n",
      "output_height: 8, output_len: 2, n layers: 10, our total_params: 68.92M\n",
      "output_height: 8, output_len: 7, n layers: 8, our total_params: 71.96M\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_pool_padding(kernel_size):\n",
    "    if kernel_size % 2 == 0:\n",
    "        pool_pad = kernel_size // 2\n",
    "    else:\n",
    "        pool_pad = (kernel_size - 1) // 2\n",
    "    return pool_pad\n",
    "\n",
    "\n",
    "def compute_layers(output_height, output_len, kernel_h, kernel_w, pool_stride_h, pool_stride_w):\n",
    "    \"\"\"\n",
    "    Compute the output shape of a CNN given lists of network parameters.\n",
    "    Args:\n",
    "        n_layers: number of layers\n",
    "        kernel_h: height of kernel\n",
    "        kernel_w: length of kernel\n",
    "        pool_stride_h: pooling stride in height\n",
    "        pool_stride_w: pooling stride in length \n",
    "    Returns:\n",
    "        output_height: height of output\n",
    "        output_len: length of output\n",
    "    \"\"\"\n",
    "    # Compute output shapes using conv formula [(Height - (Filter-1) + 2Pad)/ Stride]+1\n",
    "    conv_pad, _  = pad_utils.get_padding_value('valid_time', [kernel_h, kernel_w], stride=[1,1])\n",
    "\n",
    "    output_height = int(np.floor((output_height + (2 * conv_pad[0]) - (kernel_h - 1) - 1) / 1) + 1)\n",
    "    output_len = int(np.floor((output_len + (2 * conv_pad[1]) - (kernel_w - 1) - 1) / 1) + 1)\n",
    "\n",
    "    # pooling layers\n",
    "    pool_h = pool_stride_h * 4 if pool_stride_h > 1 else 1\n",
    "    pool_w = pool_stride_w * 4 if pool_stride_w > 1 else 1\n",
    "    # print(f'pool_h: {pool_h}, pool_w: {pool_w}')\n",
    "    # print(f'pool_stride_h: {pool_stride_h}, pool_stride_w: {pool_stride_w}')\n",
    "    # pool_pad, _  = pad_utils.get_padding_value(\"same\", [pool_h, pool_w], stride=[pool_stride_h, pool_stride_w])\n",
    "    # print(f'pool_pad: {pool_pad}')\n",
    "    pool_padding_h = get_pool_padding(pool_h)\n",
    "    pool_padding_w =  get_pool_padding(pool_w)\n",
    "    \n",
    "    output_height = int(np.floor((output_height + (2 * pool_padding_h) - pool_h) / pool_stride_h) + 1)\n",
    "    output_len = int(np.floor((output_len + (2 * pool_padding_w) - pool_w) / pool_stride_w) + 1)\n",
    "\n",
    "    return output_height, output_len, conv_pad, [pool_h, pool_w], [pool_padding_h, pool_padding_w]\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "archs = {}\n",
    "\n",
    "n_good_archs = 0\n",
    "n_tol = 1e10\n",
    "\n",
    "n_in_channels = 2 # 2 for binaural audio, 1 for mono \n",
    "fc_size = 512\n",
    "\n",
    "while n_good_archs < 4:\n",
    "    n_layers = np.random.randint(5, 11)\n",
    "    output_height = 40\n",
    "    output_len = 20000\n",
    "    params = {}\n",
    "    params['n_layers'] = n_layers\n",
    "    params['kernel'] = []\n",
    "    params['conv_pad'] = [] \n",
    "    params['pool_stride'] = []\n",
    "    params['pool_size'] = []\n",
    "    params['pool_pad'] = []\n",
    "    params['n_filts'] = []\n",
    "\n",
    "\n",
    "    try:\n",
    "        total_params = 0\n",
    "        # add input norm to params \n",
    "        total_params += (n_in_channels * output_height * output_len) * 2  \n",
    "        for layer in range(n_layers):\n",
    "            if layer == 0:\n",
    "                n_filts = 2  \n",
    "            # add layer norm (that occurs before conv)\n",
    "            total_params += (n_filts * output_height * output_len) * 2 \n",
    "\n",
    "            if layer < 2:\n",
    "                kernel_w = np.random.randint(10, 81)\n",
    "                kernel_h = np.random.randint(1, 4)\n",
    "                pool_stride_h = np.random.randint(1, 3)\n",
    "                pool_stride_w = np.random.randint(1, 7)\n",
    "\n",
    "            else:\n",
    "                kernel_h = np.random.randint(3, 7)\n",
    "                kernel_w = np.random.randint(3, 7)\n",
    "                pool_stride_h = np.random.randint(1, 2)\n",
    "                pool_stride_w = np.random.randint(1, 4)\n",
    "\n",
    "            # pool_stride_h = np.random.randint(1, 3)\n",
    "            # pool_stride_w = np.random.randint(1, 6)\n",
    "            # compute output shape\n",
    "            output_height, output_len, conv_pad, pool_size, pool_padding = compute_layers(output_height, output_len, kernel_h, kernel_w, pool_stride_h, pool_stride_w)\n",
    "\n",
    "            # update params dict \n",
    "            params['kernel'].append([kernel_h, kernel_w])\n",
    "            params['conv_pad'].append(conv_pad)\n",
    "            params['pool_stride'].append([pool_stride_h, pool_stride_w])\n",
    "            params['pool_size'].append(pool_size)\n",
    "            params['pool_pad'].append(pool_padding)\n",
    "\n",
    "            if layer == 0:\n",
    "                n_filts = 2**np.random.randint(5,7)\n",
    "                params['n_filts'].append(n_filts)\n",
    "                n_layer_params = (n_in_channels * kernel_h * kernel_w) * n_filts # no bias in these models \n",
    "            else:\n",
    "                n_filts = np.min([2 * n_filts, 512])\n",
    "                params['n_filts'].append(n_filts)\n",
    "                prev_layer_filts = params['n_filts'][layer-1]\n",
    "                n_layer_params = (prev_layer_filts * kernel_h * kernel_w) * n_filts # no bias in these models \n",
    "            \n",
    "            total_params += n_layer_params\n",
    "            \n",
    "            # add layer norm parameters \n",
    "\n",
    "         \n",
    "        ## get fully connected size for good architectures \n",
    "        final_output_size = (n_filts * output_height * output_len)\n",
    "        n_fc_params = fc_size * final_output_size\n",
    "        assert n_fc_params > 0, f'n_fc_params: {n_fc_params}, final_output_size: {final_output_size}, fc_size: {fc_size}'\n",
    "        # print(f'final_output_size: {final_output_size}, n_fc_params: {n_fc_params}')\n",
    "        total_params += n_fc_params\n",
    "        \n",
    "        # Compute fully connected to word task size \n",
    "        n_classifier_size = fc_size * 800 \n",
    "        total_params += n_classifier_size\n",
    "\n",
    "        config = deepcopy(base_config)\n",
    "        config['model']['out_channels'] = [int(i) for i in params['n_filts']]\n",
    "        # conv layers\n",
    "        config['model']['kernel'] = params['kernel']\n",
    "        config['model']['stride'] = [[1,1] for _ in  range(params['n_layers'])]\n",
    "        config['model']['padding'] = params['conv_pad']\n",
    "        config['model']['padding'] = ['valid_time' for _ in range(params['n_layers'])]\n",
    "        # pooling layers\n",
    "        config['model']['pool_stride'] = params['pool_stride']\n",
    "        config['model']['pool_size'] = params['pool_size']\n",
    "        config['model']['pool_padding'] = params['pool_pad']\n",
    "        # add attn \n",
    "        config['model']['attn'] = [1 for _ in range(params['n_layers'])]\n",
    "        # config['model']['block_order'] = \"Conv -> LN -> ReLU\"\n",
    "        config['model']['ln_affine'] = True\n",
    "        config['model']['norm_first'] = True\n",
    "\n",
    "        # if (output_height >= 2 and output_height <= 8) and (output_len >= 2 and output_len <= 8) and (total_params <= 2e8 and total_params >= 1e7):\n",
    "\n",
    "            # model = BinauralAttentionModule(config).model\n",
    "            # n_params = sum([p.numel() for p in model.parameters()])\n",
    "        if (output_height >= 2 and output_height <= 8) and (output_len >= 2 and output_len <= 8) and (total_params <= 1e8 and total_params >= 1e7):\n",
    "            print(f'output_height: {output_height}, output_len: {output_len}, n layers: {n_layers}, our total_params: {round(total_params/1e6, 2)}M')\n",
    "            # save dict of params \n",
    "            archs[f\"arch_{n_good_archs}\"] = params\n",
    "            n_good_archs += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Error: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # else:\n",
    "    n_tol -= 1\n",
    "    if n_tol == 0:\n",
    "        break \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write configs out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update existing configs with name and new dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config/arch_search/word_task_v10_4MGB_ln_first_arch_1.yaml\n",
      "config/arch_search/word_task_v10_4MGB_ln_first_arch_2.yaml\n",
      "config/arch_search/word_task_v10_4MGB_ln_first_arch_4.yaml\n",
      "config/arch_search/word_task_v10_4MGB_ln_first_arch_6.yaml\n",
      "config/arch_search/word_task_v10_4MGB_ln_first_arch_7.yaml\n",
      "config/arch_search/word_task_v10_4MGB_ln_first_arch_8.yaml\n",
      "config/arch_search/word_task_v10_4MGB_ln_first_arch_9.yaml\n"
     ]
    }
   ],
   "source": [
    "# Convert architectures in archs to configs\n",
    "from copy import deepcopy\n",
    "\n",
    "## import default config \n",
    "outdir = Path(\"config/arch_search\")\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "base_config = yaml.load(open(\"config/binaural_attn/word_task_v10_main_feature_gain_config.yaml\", 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "### Track good architecutres \n",
    "good_arch_config_names = ['word_task_v09_4MGB_ln_first_arch_1',\n",
    "                        'word_task_v09_4MGB_ln_first_arch_2',\n",
    "                        'word_task_v09_4MGB_ln_first_arch_4',\n",
    "                        'word_task_v09_4MGB_ln_first_arch_6',\n",
    "                        'word_task_v09_4MGB_ln_first_arch_7',\n",
    "                        'word_task_v09_4MGB_ln_first_arch_8',\n",
    "                        'word_task_v09_4MGB_ln_first_arch_9']\n",
    "\n",
    "for arch_name in good_arch_config_names:\n",
    "    arch_config = yaml.load(open(outdir / f\"{arch_name}.yaml\", 'r'), Loader=yaml.FullLoader)\n",
    "    # update path \n",
    "    arch_config['corpus']['root'] = base_config['corpus']['root']\n",
    "    model_name = f\"{arch_name.replace('09', '10')}\"\n",
    "    arch_config['model_name'] = model_name\n",
    "    new_config_path = outdir / f\"{model_name}.yaml\"\n",
    "    print(new_config_path)\n",
    "        # # break\n",
    "    # with open(new_config_path, 'w') as f:\n",
    "    #     yaml.dump(arch_config, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the 2 mew architectures to include with the current 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update arch of base config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config/arch_search/word_task_v10_4MGB_ln_first_arch_10.yaml\n",
      "{'corpus': {'name': 'spatialized_commonvoice_audioset_scenes', 'cue_type': 'mixed', 'task': 'word', 'root': '/om/scratch/Fri/imgriff/datasets/spatial_audio_pipeline/assets/dataset_binaural_attn/v10', 'mixture_percentages': {'voice_only': 0.5, 'voice_and_location': 0.5}, 'gender_balanced_4M': True, 'cue_free_percentage': 0.1, 'v06': True}, 'audio': {'rep_type': 'cochlea_filt', 'v2_demean': True, 'rep_kwargs': {'sr': 44100, 'env_sr': 10000, 'n_channels': 40, 'low_lim': 40, 'use_pad': True, 'binaural': True, 'rep_on_gpu': True, 'center_crop': True, 'out_dur': 2, 'impulse_len': 0.25, 'env_extraction_type': 'Half-wave Rectification', 'downsampling_type': 'TorchTransformsResample', 'downsampling_kwargs': {'lowpass_filter_width': 64, 'rolloff': 0.9475937167399596, 'resampling_method': 'kaiser_window', 'beta': 14.769656459379492}}, 'compression_type': 'coch_p3', 'compression_kwargs': {'scale': 1, 'offset': 1e-07, 'clip_value': 5, 'power': 0.3}}, 'val_metric': 'val_acc', 'model_name': 'word_task_v10_4MGB_ln_first_arch_10', 'noise_kwargs': {'low_snr': -10, 'high_snr': 10}, 'hparas': {'valid_step': 4000, 'epochs': 1000, 'optimizer': 'AdamW', 'lr': 5e-06, 'eps': 1e-07, 'gradient_clip_val': 100, 'batch_size': 288, 'mask_cues': False}, 'model': {'input_sr': 10000, 'out_channels': [32, 64, 128, 256, 512, 512, 512, 512, 512], 'kernel': [[1, 16], [2, 79], [5, 4], [6, 6], [6, 4], [3, 5], [4, 4], [5, 3], [5, 6]], 'stride': [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], 'padding': ['valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time'], 'pool_stride': [[2, 3], [2, 5], [1, 2], [1, 2], [1, 3], [1, 2], [1, 2], [1, 2], [1, 2]], 'pool_size': [[8, 12], [8, 20], [1, 8], [1, 8], [1, 12], [1, 8], [1, 8], [1, 8], [1, 8]], 'pool_padding': [[4, 6], [4, 10], [0, 4], [0, 4], [0, 6], [0, 4], [0, 4], [0, 4], [0, 4]], 'attn': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'num_classes': {'num_words': 800}, 'fc_size': 512, 'global_avg_cue': False, 'dropout': 0.5, 'attn_constraints': {'slope': True}, 'v08': True, 'norm_first': True, 'ln_affine': True}}\n",
      "config/arch_search/word_task_v10_4MGB_ln_first_arch_11.yaml\n",
      "{'corpus': {'name': 'spatialized_commonvoice_audioset_scenes', 'cue_type': 'mixed', 'task': 'word', 'root': '/om/scratch/Fri/imgriff/datasets/spatial_audio_pipeline/assets/dataset_binaural_attn/v10', 'mixture_percentages': {'voice_only': 0.5, 'voice_and_location': 0.5}, 'gender_balanced_4M': True, 'cue_free_percentage': 0.1, 'v06': True}, 'audio': {'rep_type': 'cochlea_filt', 'v2_demean': True, 'rep_kwargs': {'sr': 44100, 'env_sr': 10000, 'n_channels': 40, 'low_lim': 40, 'use_pad': True, 'binaural': True, 'rep_on_gpu': True, 'center_crop': True, 'out_dur': 2, 'impulse_len': 0.25, 'env_extraction_type': 'Half-wave Rectification', 'downsampling_type': 'TorchTransformsResample', 'downsampling_kwargs': {'lowpass_filter_width': 64, 'rolloff': 0.9475937167399596, 'resampling_method': 'kaiser_window', 'beta': 14.769656459379492}}, 'compression_type': 'coch_p3', 'compression_kwargs': {'scale': 1, 'offset': 1e-07, 'clip_value': 5, 'power': 0.3}}, 'val_metric': 'val_acc', 'model_name': 'word_task_v10_4MGB_ln_first_arch_11', 'noise_kwargs': {'low_snr': -10, 'high_snr': 10}, 'hparas': {'valid_step': 4000, 'epochs': 1000, 'optimizer': 'AdamW', 'lr': 5e-06, 'eps': 1e-07, 'gradient_clip_val': 100, 'batch_size': 288, 'mask_cues': False}, 'model': {'input_sr': 10000, 'out_channels': [64, 128, 256, 512, 512, 512, 512, 512, 512, 512], 'kernel': [[1, 71], [3, 51], [3, 3], [3, 4], [3, 6], [4, 5], [5, 5], [6, 5], [6, 6], [3, 6]], 'stride': [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], 'padding': ['valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time'], 'pool_stride': [[2, 4], [2, 6], [1, 3], [1, 2], [1, 1], [1, 2], [1, 1], [1, 2], [1, 2], [1, 3]], 'pool_size': [[8, 16], [8, 24], [1, 12], [1, 8], [1, 1], [1, 8], [1, 1], [1, 8], [1, 8], [1, 12]], 'pool_padding': [[4, 8], [4, 12], [0, 6], [0, 4], [0, 0], [0, 4], [0, 0], [0, 4], [0, 4], [0, 6]], 'attn': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'num_classes': {'num_words': 800}, 'fc_size': 512, 'global_avg_cue': False, 'dropout': 0.5, 'attn_constraints': {'slope': True}, 'v08': True, 'norm_first': True, 'ln_affine': True}}\n",
      "config/arch_search/word_task_v10_4MGB_ln_first_arch_12.yaml\n",
      "{'corpus': {'name': 'spatialized_commonvoice_audioset_scenes', 'cue_type': 'mixed', 'task': 'word', 'root': '/om/scratch/Fri/imgriff/datasets/spatial_audio_pipeline/assets/dataset_binaural_attn/v10', 'mixture_percentages': {'voice_only': 0.5, 'voice_and_location': 0.5}, 'gender_balanced_4M': True, 'cue_free_percentage': 0.1, 'v06': True}, 'audio': {'rep_type': 'cochlea_filt', 'v2_demean': True, 'rep_kwargs': {'sr': 44100, 'env_sr': 10000, 'n_channels': 40, 'low_lim': 40, 'use_pad': True, 'binaural': True, 'rep_on_gpu': True, 'center_crop': True, 'out_dur': 2, 'impulse_len': 0.25, 'env_extraction_type': 'Half-wave Rectification', 'downsampling_type': 'TorchTransformsResample', 'downsampling_kwargs': {'lowpass_filter_width': 64, 'rolloff': 0.9475937167399596, 'resampling_method': 'kaiser_window', 'beta': 14.769656459379492}}, 'compression_type': 'coch_p3', 'compression_kwargs': {'scale': 1, 'offset': 1e-07, 'clip_value': 5, 'power': 0.3}}, 'val_metric': 'val_acc', 'model_name': 'word_task_v10_4MGB_ln_first_arch_12', 'noise_kwargs': {'low_snr': -10, 'high_snr': 10}, 'hparas': {'valid_step': 4000, 'epochs': 1000, 'optimizer': 'AdamW', 'lr': 5e-06, 'eps': 1e-07, 'gradient_clip_val': 100, 'batch_size': 288, 'mask_cues': False}, 'model': {'input_sr': 10000, 'out_channels': [32, 64, 128, 256, 512, 512, 512, 512, 512, 512], 'kernel': [[3, 75], [2, 44], [5, 4], [4, 6], [5, 6], [5, 5], [3, 3], [6, 6], [4, 4], [5, 5]], 'stride': [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], 'padding': ['valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time'], 'pool_stride': [[2, 2], [2, 6], [1, 2], [1, 3], [1, 1], [1, 3], [1, 2], [1, 3], [1, 2], [1, 1]], 'pool_size': [[8, 8], [8, 24], [1, 8], [1, 12], [1, 1], [1, 12], [1, 8], [1, 12], [1, 8], [1, 1]], 'pool_padding': [[4, 4], [4, 12], [0, 4], [0, 6], [0, 0], [0, 6], [0, 4], [0, 6], [0, 4], [0, 0]], 'attn': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'num_classes': {'num_words': 800}, 'fc_size': 512, 'global_avg_cue': False, 'dropout': 0.5, 'attn_constraints': {'slope': True}, 'v08': True, 'norm_first': True, 'ln_affine': True}}\n",
      "config/arch_search/word_task_v10_4MGB_ln_first_arch_13.yaml\n",
      "{'corpus': {'name': 'spatialized_commonvoice_audioset_scenes', 'cue_type': 'mixed', 'task': 'word', 'root': '/om/scratch/Fri/imgriff/datasets/spatial_audio_pipeline/assets/dataset_binaural_attn/v10', 'mixture_percentages': {'voice_only': 0.5, 'voice_and_location': 0.5}, 'gender_balanced_4M': True, 'cue_free_percentage': 0.1, 'v06': True}, 'audio': {'rep_type': 'cochlea_filt', 'v2_demean': True, 'rep_kwargs': {'sr': 44100, 'env_sr': 10000, 'n_channels': 40, 'low_lim': 40, 'use_pad': True, 'binaural': True, 'rep_on_gpu': True, 'center_crop': True, 'out_dur': 2, 'impulse_len': 0.25, 'env_extraction_type': 'Half-wave Rectification', 'downsampling_type': 'TorchTransformsResample', 'downsampling_kwargs': {'lowpass_filter_width': 64, 'rolloff': 0.9475937167399596, 'resampling_method': 'kaiser_window', 'beta': 14.769656459379492}}, 'compression_type': 'coch_p3', 'compression_kwargs': {'scale': 1, 'offset': 1e-07, 'clip_value': 5, 'power': 0.3}}, 'val_metric': 'val_acc', 'model_name': 'word_task_v10_4MGB_ln_first_arch_13', 'noise_kwargs': {'low_snr': -10, 'high_snr': 10}, 'hparas': {'valid_step': 4000, 'epochs': 1000, 'optimizer': 'AdamW', 'lr': 5e-06, 'eps': 1e-07, 'gradient_clip_val': 100, 'batch_size': 288, 'mask_cues': False}, 'model': {'input_sr': 10000, 'out_channels': [64, 128, 256, 512, 512, 512, 512, 512], 'kernel': [[2, 41], [2, 20], [3, 3], [5, 4], [6, 3], [5, 3], [6, 5], [5, 3]], 'stride': [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], 'padding': ['valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time', 'valid_time'], 'pool_stride': [[2, 3], [2, 6], [1, 2], [1, 2], [1, 3], [1, 3], [1, 2], [1, 2]], 'pool_size': [[8, 12], [8, 24], [1, 8], [1, 8], [1, 12], [1, 12], [1, 8], [1, 8]], 'pool_padding': [[4, 6], [4, 12], [0, 4], [0, 4], [0, 6], [0, 6], [0, 4], [0, 4]], 'attn': [1, 1, 1, 1, 1, 1, 1, 1], 'num_classes': {'num_words': 800}, 'fc_size': 512, 'global_avg_cue': False, 'dropout': 0.5, 'attn_constraints': {'slope': True}, 'v08': True, 'norm_first': True, 'ln_affine': True}}\n"
     ]
    }
   ],
   "source": [
    "# Convert architectures in archs to configs\n",
    "from copy import deepcopy\n",
    "\n",
    "## import default config \n",
    "outdir = Path(\"config/arch_search\")\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "base_config = yaml.load(open(\"config/binaural_attn/word_task_v10_main_feature_gain_config.yaml\", 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "### We will index thest architectures by the number of the architecture satrting at 10, so they will be sequential additions to the existing 10 tried (numbered 0-9)\n",
    "\n",
    "for i, (arch_name, params) in enumerate(archs.items()):\n",
    "    config = deepcopy(base_config)\n",
    "    config['model']['out_channels'] = [int(i) for i in params['n_filts']]\n",
    "    # conv layers\n",
    "    config['model']['kernel'] = params['kernel']\n",
    "    config['model']['stride'] = [[1,1] for _ in  range(params['n_layers'])]\n",
    "    config['model']['padding'] = params['conv_pad']\n",
    "    config['model']['padding'] = ['valid_time' for _ in range(params['n_layers'])]\n",
    "    # pooling layers\n",
    "    config['model']['pool_stride'] = params['pool_stride']\n",
    "    config['model']['pool_size'] = params['pool_size']\n",
    "    config['model']['pool_padding'] = params['pool_pad']\n",
    "    # add attn \n",
    "    config['model']['attn'] = [1 for _ in range(params['n_layers'])]\n",
    "\n",
    "    # update learning rate \n",
    "    config['hparas']['valid_step'] = 4000\n",
    "\n",
    "    # config['model']\n",
    "     # write config to file\n",
    "    model_name = f\"word_task_v10_4MGB_ln_first_arch_{10 + i:2}\"\n",
    "    config['model_name'] = model_name\n",
    "    config_name = outdir / f\"{model_name}.yaml\"\n",
    "    print(config_name)\n",
    "    print(config)\n",
    "    # # break\n",
    "    with open(config_name, 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure configs are compat with model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node063\n"
     ]
    }
   ],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.spatial_attn_lightning import BinauralAttentionModule\n",
    "import yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wanted_configs = list(outdir.glob('*v10*.yaml'))\n",
    "len(wanted_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Using singe gain function per layer\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "80.97 M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Using singe gain function per layer\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "58.18 M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Using singe gain function per layer\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "76.67 M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Using singe gain function per layer\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "56.31 M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Using singe gain function per layer\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "87.28 M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Using singe gain function per layer\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "52.07 M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Using singe gain function per layer\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "73.74 M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Using singe gain function per layer\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "50.93 M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Using singe gain function per layer\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "66.14 M\n"
     ]
    }
   ],
   "source": [
    "for config_path in wanted_configs:\n",
    "    config = yaml.load(open(config_path, 'r'), Loader=yaml.FullLoader)\n",
    "    n_params = 0\n",
    "    for param in BinauralAttentionModule(config).model.parameters():\n",
    "        n_params += param.numel()\n",
    "    print(f\"{n_params/1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
