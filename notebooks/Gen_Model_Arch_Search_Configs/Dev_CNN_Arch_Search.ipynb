{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/imgriff/conda_envs/torch_11_cuda_11_pitch/lib/python3.9/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import sklearn as sk\n",
    "# from skopt import gp_minimize, forest_minimize\n",
    "from src.layers import padding as pad_utils\n",
    "from src.spatial_attn_lightning import BinauralAttentionModule\n",
    "import yaml "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly generate architectures\n",
    "\n",
    "### Required conditions:\n",
    "* N parameters < 200M\n",
    "* 4 < N layers < 11\n",
    "* 2 < output height < 8\n",
    "* 2 < output width < 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write configs \n",
    "\n",
    "from pathlib import Path\n",
    "import yaml \n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "## import default config \n",
    "outdir = Path(\"config/arch_search\")\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "base_config = yaml.load(open(\"config/binaural_attn/word_task_half_co_loc_v09_gender_bal_4M_w_no_cue_learned_higher_lr_less_dropout.yaml\", 'r'), Loader=yaml.FullLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "output_height: 7, output_len: 4, n layers: 10, our n_params: 37.53M, actual n_params: 144.71M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "output_height: 6, output_len: 4, n layers: 10, our n_params: 33.49M, actual n_params: 80.97M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "output_height: 5, output_len: 5, n layers: 9, our n_params: 39.59M, actual n_params: 56.31M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "output_height: 8, output_len: 4, n layers: 9, our n_params: 41.75M, actual n_params: 79.80M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "output_height: 6, output_len: 3, n layers: 10, our n_params: 45.37M, actual n_params: 87.28M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "output_height: 6, output_len: 8, n layers: 8, our n_params: 38.45M, actual n_params: 89.14M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "output_height: 8, output_len: 4, n layers: 8, our n_params: 31.39M, actual n_params: 52.07M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "output_height: 8, output_len: 6, n layers: 10, our n_params: 36.37M, actual n_params: 73.74M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "output_height: 7, output_len: 2, n layers: 10, our n_params: 36.34M, actual n_params: 50.93M\n",
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "fc_attn: True\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "output_height: 7, output_len: 4, n layers: 10, our n_params: 33.56M, actual n_params: 66.14M\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_pool_padding(kernel_size):\n",
    "    if kernel_size % 2 == 0:\n",
    "        pool_pad = kernel_size // 2\n",
    "    else:\n",
    "        pool_pad = (kernel_size - 1) // 2\n",
    "    return pool_pad\n",
    "\n",
    "\n",
    "def compute_layers(output_height, output_len, kernel_h, kernel_w, pool_stride_h, pool_stride_w):\n",
    "    \"\"\"\n",
    "    Compute the output shape of a CNN given lists of network parameters.\n",
    "    Args:\n",
    "        n_layers: number of layers\n",
    "        kernel_h: height of kernel\n",
    "        kernel_w: length of kernel\n",
    "        pool_stride_h: pooling stride in height\n",
    "        pool_stride_w: pooling stride in length \n",
    "    Returns:\n",
    "        output_height: height of output\n",
    "        output_len: length of output\n",
    "    \"\"\"\n",
    "    # Compute output shapes using conv formula [(Height - (Filter-1) + 2Pad)/ Stride]+1\n",
    "    conv_pad, _  = pad_utils.get_padding_value('valid_time', [kernel_h, kernel_w], stride=[1,1])\n",
    "\n",
    "    output_height = int(np.floor((output_height + (2 * conv_pad[0]) - (kernel_h - 1) - 1) / 1) + 1)\n",
    "    output_len = int(np.floor((output_len + (2 * conv_pad[1]) - (kernel_w - 1) - 1) / 1) + 1)\n",
    "\n",
    "    # pooling layers\n",
    "    pool_h = pool_stride_h * 4 if pool_stride_h > 1 else 1\n",
    "    pool_w = pool_stride_w * 4 if pool_stride_w > 1 else 1\n",
    "    # print(f'pool_h: {pool_h}, pool_w: {pool_w}')\n",
    "    # print(f'pool_stride_h: {pool_stride_h}, pool_stride_w: {pool_stride_w}')\n",
    "    # pool_pad, _  = pad_utils.get_padding_value(\"same\", [pool_h, pool_w], stride=[pool_stride_h, pool_stride_w])\n",
    "    # print(f'pool_pad: {pool_pad}')\n",
    "    pool_padding_h = get_pool_padding(pool_h)\n",
    "    pool_padding_w =  get_pool_padding(pool_w)\n",
    "    \n",
    "    output_height = int(np.floor((output_height + (2 * pool_padding_h) - pool_h) / pool_stride_h) + 1)\n",
    "    output_len = int(np.floor((output_len + (2 * pool_padding_w) - pool_w) / pool_stride_w) + 1)\n",
    "\n",
    "    return output_height, output_len, conv_pad, [pool_h, pool_w], [pool_padding_h, pool_padding_w]\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(10)\n",
    "archs = {}\n",
    "\n",
    "n_good_archs = 0\n",
    "n_tol = 1e10\n",
    "\n",
    "n_in_channels = 2 # 2 for binaural audio, 1 for mono \n",
    "fc_size = 512\n",
    "\n",
    "while n_good_archs < 10:\n",
    "    n_layers = np.random.randint(5, 11)\n",
    "    output_height = 40\n",
    "    output_len = 20000\n",
    "    params = {}\n",
    "    params['n_layers'] = n_layers\n",
    "    params['kernel'] = []\n",
    "    params['conv_pad'] = [] \n",
    "    params['pool_stride'] = []\n",
    "    params['pool_size'] = []\n",
    "    params['pool_pad'] = []\n",
    "    params['n_filts'] = []\n",
    "\n",
    "    try:\n",
    "        total_params = 0\n",
    "        # add input norm to params \n",
    "        # total_params += n_in_channels * output_height * output_len\n",
    "        for layer in range(n_layers):\n",
    "            if layer < 2:\n",
    "                kernel_w = np.random.randint(10, 81)\n",
    "                kernel_h = np.random.randint(1, 4)\n",
    "                pool_stride_h = np.random.randint(1, 3)\n",
    "                pool_stride_w = np.random.randint(1, 7)\n",
    "\n",
    "            else:\n",
    "                kernel_h = np.random.randint(3, 7)\n",
    "                kernel_w = np.random.randint(3, 7)\n",
    "                pool_stride_h = np.random.randint(1, 2)\n",
    "                pool_stride_w = np.random.randint(1, 4)\n",
    "\n",
    "            # pool_stride_h = np.random.randint(1, 3)\n",
    "            # pool_stride_w = np.random.randint(1, 6)\n",
    "            # compute output shape\n",
    "            output_height, output_len, conv_pad, pool_size, pool_padding = compute_layers(output_height, output_len, kernel_h, kernel_w, pool_stride_h, pool_stride_w)\n",
    "\n",
    "            # update params dict \n",
    "            params['kernel'].append([kernel_h, kernel_w])\n",
    "            params['conv_pad'].append(conv_pad)\n",
    "            params['pool_stride'].append([pool_stride_h, pool_stride_w])\n",
    "            params['pool_size'].append(pool_size)\n",
    "            params['pool_pad'].append(pool_padding)\n",
    "\n",
    "            if layer == 0:\n",
    "                n_filts = 2**np.random.randint(5,7)\n",
    "                params['n_filts'].append(n_filts)\n",
    "                n_layer_params = (n_in_channels * kernel_h * kernel_w) * n_filts # no bias in these models \n",
    "            else:\n",
    "                n_filts = np.min([2 * n_filts, 512])\n",
    "                params['n_filts'].append(n_filts)\n",
    "                prev_layer_filts = params['n_filts'][layer-1]\n",
    "                n_layer_params = (prev_layer_filts * kernel_h * kernel_w) * n_filts # no bias in these models \n",
    "            \n",
    "            total_params += n_layer_params\n",
    "\n",
    "         \n",
    "        ## get fully connected size for good architectures \n",
    "        final_output_size = (n_filts * output_height * output_len)\n",
    "        n_fc_params = fc_size * final_output_size\n",
    "        assert n_fc_params > 0, f'n_fc_params: {n_fc_params}, final_output_size: {final_output_size}, fc_size: {fc_size}'\n",
    "        # print(f'final_output_size: {final_output_size}, n_fc_params: {n_fc_params}')\n",
    "        total_params += n_fc_params\n",
    "\n",
    "        config = deepcopy(base_config)\n",
    "        config['model']['out_channels'] = [int(i) for i in params['n_filts']]\n",
    "        # conv layers\n",
    "        config['model']['kernel'] = params['kernel']\n",
    "        config['model']['stride'] = [[1,1] for _ in  range(params['n_layers'])]\n",
    "        config['model']['padding'] = params['conv_pad']\n",
    "        config['model']['padding'] = ['valid_time' for _ in range(params['n_layers'])]\n",
    "        # pooling layers\n",
    "        config['model']['pool_stride'] = params['pool_stride']\n",
    "        config['model']['pool_size'] = params['pool_size']\n",
    "        config['model']['pool_padding'] = params['pool_pad']\n",
    "        # add attn \n",
    "        config['model']['attn'] = [1 for _ in range(params['n_layers'])]\n",
    "        # config['model']['block_order'] = \"Conv -> LN -> ReLU\"\n",
    "        config['model']['ln_affine'] = True\n",
    "        config['model']['norm_first'] = True\n",
    "\n",
    "        if (output_height >= 2 and output_height <= 8) and (output_len >= 2 and output_len <= 8) and (total_params <= 2e8 and total_params >= 1e7):\n",
    "\n",
    "            model = BinauralAttentionModule(config).model\n",
    "            n_params = sum([p.numel() for p in model.parameters()])\n",
    "            if (output_height >= 2 and output_height <= 8) and (output_len >= 2 and output_len <= 8) and (n_params <= 1.5e8 and n_params >= 1e7):\n",
    "                print(f'output_height: {output_height}, output_len: {output_len}, n layers: {n_layers}, our n_params: {round(total_params/1e6, 2)}M, actual n_params: {n_params/1e6:.2f}M')\n",
    "                # save dict of params \n",
    "                archs[f\"arch_{n_good_archs}\"] = params\n",
    "                n_good_archs += 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        # print(f\"Error: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # else:\n",
    "    n_tol -= 1\n",
    "    if n_tol == 0:\n",
    "        break \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update arch of base config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_sr': 10000,\n",
       " 'out_channels': [32, 64, 256, 512, 512, 512, 512],\n",
       " 'kernel': [[2, 34], [2, 14], [5, 5], [5, 5], [6, 6], [5, 5], [6, 6]],\n",
       " 'stride': [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]],\n",
       " 'padding': ['valid_time',\n",
       "  'valid_time',\n",
       "  'valid_time',\n",
       "  'valid_time',\n",
       "  'valid_time',\n",
       "  'valid_time',\n",
       "  'valid_time'],\n",
       " 'pool_stride': [[2, 4], [2, 4], [1, 5], [1, 4], [1, 1], [1, 1], [2, 4]],\n",
       " 'pool_size': [[9, 13], [9, 13], [1, 13], [1, 13], [1, 1], [1, 1], [6, 13]],\n",
       " 'pool_padding': [[4, 6], [4, 6], [0, 6], [0, 6], [0, 0], [0, 0], [3, 6]],\n",
       " 'attn': [1, 1, 1, 1, 1, 1, 1],\n",
       " 'num_classes': {'num_words': 800},\n",
       " 'fc_size': 512,\n",
       " 'global_avg_cue': False,\n",
       " 'dropout': 0.5,\n",
       " 'attn_constraints': {'slope': True},\n",
       " 'v08': True,\n",
       " 'norm_first': True,\n",
       " 'ln_affine': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_config[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config/arch_search/word_task_v09_4MGB_ln_first_arch_0.yaml\n",
      "config/arch_search/word_task_v09_4MGB_ln_first_arch_1.yaml\n",
      "config/arch_search/word_task_v09_4MGB_ln_first_arch_2.yaml\n",
      "config/arch_search/word_task_v09_4MGB_ln_first_arch_3.yaml\n",
      "config/arch_search/word_task_v09_4MGB_ln_first_arch_4.yaml\n",
      "config/arch_search/word_task_v09_4MGB_ln_first_arch_5.yaml\n",
      "config/arch_search/word_task_v09_4MGB_ln_first_arch_6.yaml\n",
      "config/arch_search/word_task_v09_4MGB_ln_first_arch_7.yaml\n",
      "config/arch_search/word_task_v09_4MGB_ln_first_arch_8.yaml\n",
      "config/arch_search/word_task_v09_4MGB_ln_first_arch_9.yaml\n"
     ]
    }
   ],
   "source": [
    "# Convert architectures in archs to configs\n",
    "from copy import deepcopy\n",
    "\n",
    "## import default config \n",
    "outdir = Path(\"config/arch_search\")\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "base_config = yaml.load(open(\"config/binaural_attn/word_task_half_co_loc_v09_gender_bal_4M_w_no_cue_learned_higher_lr_less_dropout.yaml\", 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "for arch in archs:\n",
    "    params = archs[arch]\n",
    "    config = deepcopy(base_config)\n",
    "    config['model']['out_channels'] = [int(i) for i in params['n_filts']]\n",
    "    # conv layers\n",
    "    config['model']['kernel'] = params['kernel']\n",
    "    config['model']['stride'] = [[1,1] for _ in  range(params['n_layers'])]\n",
    "    config['model']['padding'] = params['conv_pad']\n",
    "    config['model']['padding'] = ['valid_time' for _ in range(params['n_layers'])]\n",
    "    # pooling layers\n",
    "    config['model']['pool_stride'] = params['pool_stride']\n",
    "    config['model']['pool_size'] = params['pool_size']\n",
    "    config['model']['pool_padding'] = params['pool_pad']\n",
    "    # add attn \n",
    "    config['model']['attn'] = [1 for _ in range(params['n_layers'])]\n",
    "\n",
    "    # update learning rate \n",
    "    config['hparas']['valid_step'] = 4000\n",
    "\n",
    "    # config['model']\n",
    "     # write config to file\n",
    "    config_name = outdir / f\"word_task_v09_4MGB_ln_first_{arch:2}.yaml\"\n",
    "    print(config_name)\n",
    "    # break\n",
    "    with open(config_name, 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_sr': 10000,\n",
       " 'out_channels': [32, 64, 128, 256, 512, 512, 512, 512, 512, 512],\n",
       " 'kernel': [[2, 11],\n",
       "  [3, 60],\n",
       "  [4, 5],\n",
       "  [4, 4],\n",
       "  [3, 4],\n",
       "  [4, 3],\n",
       "  [5, 3],\n",
       "  [4, 6],\n",
       "  [3, 3],\n",
       "  [5, 6]],\n",
       " 'stride': [[1, 1],\n",
       "  [1, 1],\n",
       "  [1, 1],\n",
       "  [1, 1],\n",
       "  [1, 1],\n",
       "  [1, 1],\n",
       "  [1, 1],\n",
       "  [1, 1],\n",
       "  [1, 1],\n",
       "  [1, 1]],\n",
       " 'padding': ['valid_time',\n",
       "  'valid_time',\n",
       "  'valid_time',\n",
       "  'valid_time',\n",
       "  'valid_time',\n",
       "  'valid_time',\n",
       "  'valid_time',\n",
       "  'valid_time',\n",
       "  'valid_time',\n",
       "  'valid_time'],\n",
       " 'pool_stride': [[2, 2],\n",
       "  [2, 6],\n",
       "  [1, 1],\n",
       "  [1, 3],\n",
       "  [1, 3],\n",
       "  [1, 1],\n",
       "  [1, 3],\n",
       "  [1, 3],\n",
       "  [1, 2],\n",
       "  [1, 1]],\n",
       " 'pool_size': [[8, 8],\n",
       "  [8, 24],\n",
       "  [1, 1],\n",
       "  [1, 12],\n",
       "  [1, 12],\n",
       "  [1, 1],\n",
       "  [1, 12],\n",
       "  [1, 12],\n",
       "  [1, 8],\n",
       "  [1, 1]],\n",
       " 'pool_padding': [[4, 4],\n",
       "  [4, 12],\n",
       "  [0, 0],\n",
       "  [0, 6],\n",
       "  [0, 6],\n",
       "  [0, 0],\n",
       "  [0, 6],\n",
       "  [0, 6],\n",
       "  [0, 4],\n",
       "  [0, 0]],\n",
       " 'attn': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'num_classes': {'num_words': 800},\n",
       " 'fc_size': 512,\n",
       " 'global_avg_cue': False,\n",
       " 'dropout': 0.5,\n",
       " 'attn_constraints': {'slope': True},\n",
       " 'v08': True,\n",
       " 'norm_first': True,\n",
       " 'ln_affine': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure configs are compat with model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node111\n"
     ]
    }
   ],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.spatial_attn_lightning import BinauralAttentionModule\n",
    "import yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corpus': {'name': 'spatialized_commonvoice_audioset_scenes',\n",
       "  'cue_type': 'mixed',\n",
       "  'task': 'word',\n",
       "  'root': '/om/scratch/Sun/imgriff/datasets/spatial_audio_pipeline/assets/dataset_binaural_attn/v08',\n",
       "  'mixture_percentages': {'voice_only': 0.5, 'voice_and_location': 0.5},\n",
       "  'gender_balanced_4M': True,\n",
       "  'cue_free_percentage': 0.1,\n",
       "  'v06': True},\n",
       " 'audio': {'rep_type': 'cochlea_filt',\n",
       "  'v2_demean': True,\n",
       "  'rep_kwargs': {'sr': 44100,\n",
       "   'env_sr': 10000,\n",
       "   'n_channels': 40,\n",
       "   'low_lim': 40,\n",
       "   'use_pad': True,\n",
       "   'binaural': True,\n",
       "   'rep_on_gpu': True,\n",
       "   'center_crop': True,\n",
       "   'out_dur': 2,\n",
       "   'impulse_len': 0.25,\n",
       "   'env_extraction_type': 'Half-wave Rectification',\n",
       "   'downsampling_type': 'TorchTransformsResample',\n",
       "   'downsampling_kwargs': {'lowpass_filter_width': 64,\n",
       "    'rolloff': 0.9475937167399596,\n",
       "    'resampling_method': 'kaiser_window',\n",
       "    'beta': 14.769656459379492}},\n",
       "  'compression_type': 'coch_p3',\n",
       "  'compression_kwargs': {'scale': 1,\n",
       "   'offset': 1e-07,\n",
       "   'clip_value': 5,\n",
       "   'power': 0.3}},\n",
       " 'val_metric': 'val_acc',\n",
       " 'model_name': 'gender_balanced_training_v09_4M_no_cue_learned',\n",
       " 'noise_kwargs': {'low_snr': -10, 'high_snr': 10},\n",
       " 'hparas': {'valid_step': 2000,\n",
       "  'epochs': 1000,\n",
       "  'optimizer': 'AdamW',\n",
       "  'lr': 5e-05,\n",
       "  'eps': 1e-07,\n",
       "  'gradient_clip_val': 100,\n",
       "  'batch_size': 288,\n",
       "  'mask_cues': False},\n",
       " 'model': {'input_sr': 10000,\n",
       "  'out_channels': [64, 128, 256, 512, 512, 512, 512, 512, 512],\n",
       "  'kernel': [[3, 72],\n",
       "   [2, 52],\n",
       "   [4, 5],\n",
       "   [3, 4],\n",
       "   [4, 3],\n",
       "   [6, 6],\n",
       "   [3, 3],\n",
       "   [3, 5],\n",
       "   [5, 4]],\n",
       "  'stride': [[1, 1],\n",
       "   [1, 1],\n",
       "   [1, 1],\n",
       "   [1, 1],\n",
       "   [1, 1],\n",
       "   [1, 1],\n",
       "   [1, 1],\n",
       "   [1, 1],\n",
       "   [1, 1]],\n",
       "  'padding': ['valid_time',\n",
       "   'valid_time',\n",
       "   'valid_time',\n",
       "   'valid_time',\n",
       "   'valid_time',\n",
       "   'valid_time',\n",
       "   'valid_time',\n",
       "   'valid_time',\n",
       "   'valid_time'],\n",
       "  'pool_stride': [[2, 2],\n",
       "   [2, 4],\n",
       "   [1, 2],\n",
       "   [1, 2],\n",
       "   [1, 3],\n",
       "   [1, 2],\n",
       "   [1, 3],\n",
       "   [1, 2],\n",
       "   [1, 2]],\n",
       "  'pool_size': [[8, 8],\n",
       "   [8, 16],\n",
       "   [1, 8],\n",
       "   [1, 8],\n",
       "   [1, 12],\n",
       "   [1, 8],\n",
       "   [1, 12],\n",
       "   [1, 8],\n",
       "   [1, 8]],\n",
       "  'pool_padding': [[4, 4],\n",
       "   [4, 8],\n",
       "   [0, 4],\n",
       "   [0, 4],\n",
       "   [0, 6],\n",
       "   [0, 4],\n",
       "   [0, 6],\n",
       "   [0, 4],\n",
       "   [0, 4]],\n",
       "  'attn': [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  'num_classes': {'num_words': 800},\n",
       "  'fc_size': 512,\n",
       "  'global_avg_cue': False,\n",
       "  'dropout': 0.5,\n",
       "  'attn_constraints': {'slope': True},\n",
       "  'v08': True,\n",
       "  'norm_first': True,\n",
       "  'ln_affine': True}}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using explicit dim specification for demeaning in audio transforms\n",
      "Using BinauralAuditoryAttentionCNN\n",
      "v08 True\n",
      "num_classes={'num_words': 800}\n",
      "Model performing word task\n",
      "Conv block order: LN -> Conv -> ReLU\n",
      "coch_affine: True\n",
      "center_crop=True\n",
      "binaural=True\n",
      "Binaural cochleagram\n",
      "using FIR cochleagram\n",
      "98.29 M\n"
     ]
    }
   ],
   "source": [
    "n_params = 0\n",
    "for param in BinauralAttentionModule(config).model.parameters():\n",
    "    n_params += param.numel()\n",
    "print(f\"{n_params/1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N pitch classes = 8\n",
      "height = 50, width = 100000\n",
      "height = 49, width = 99996\n",
      "height = 25, width = 33329\n",
      "height = 21, width = 33305\n",
      "height = 21, width = 16649\n",
      "height = 21, width = 16624\n",
      "height = 11, width = 4153\n",
      "height = 10, width = 4127\n",
      "height = 10, width = 4127\n",
      "height = 7, width = 4082\n",
      "height = 4, width = 2038\n",
      "height = 2, width = 2018\n",
      "height = 2, width = 400\n",
      "center_crop=True\n",
      "binaural=False\n",
      "using FIR cochleagram\n",
      "N pitch classes = 8\n",
      "height = 50, width = 100000\n",
      "height = 48, width = 99934\n",
      "height = 48, width = 99934\n",
      "height = 45, width = 99865\n",
      "height = 23, width = 24963\n",
      "height = 20, width = 24933\n",
      "height = 20, width = 12463\n",
      "height = 19, width = 12426\n",
      "height = 10, width = 2068\n",
      "height = 9, width = 2056\n",
      "height = 9, width = 2056\n",
      "height = 7, width = 2017\n",
      "height = 4, width = 400\n",
      "center_crop=True\n",
      "binaural=False\n",
      "using FIR cochleagram\n",
      "N pitch classes = 8\n",
      "height = 50, width = 100000\n",
      "height = 49, width = 99956\n",
      "height = 25, width = 24986\n",
      "height = 22, width = 24925\n",
      "height = 22, width = 4982\n",
      "height = 19, width = 4933\n",
      "height = 19, width = 4933\n",
      "height = 16, width = 4881\n",
      "height = 16, width = 4881\n",
      "height = 15, width = 4877\n",
      "height = 8, width = 1216\n",
      "height = 6, width = 1211\n",
      "height = 6, width = 400\n",
      "center_crop=True\n",
      "binaural=False\n",
      "using FIR cochleagram\n",
      "N pitch classes = 8\n",
      "height = 50, width = 100000\n",
      "height = 49, width = 99931\n",
      "height = 49, width = 49962\n",
      "height = 45, width = 49896\n",
      "height = 45, width = 49896\n",
      "height = 41, width = 49844\n",
      "height = 41, width = 16611\n",
      "height = 38, width = 16571\n",
      "height = 20, width = 3311\n",
      "height = 20, width = 3262\n",
      "height = 11, width = 3262\n",
      "height = 8, width = 3249\n",
      "height = 8, width = 1621\n",
      "height = 5, width = 1614\n",
      "height = 5, width = 400\n",
      "center_crop=True\n",
      "binaural=False\n",
      "using FIR cochleagram\n",
      "N pitch classes = 8\n",
      "height = 50, width = 100000\n",
      "height = 47, width = 99926\n",
      "height = 47, width = 16651\n",
      "height = 43, width = 16586\n",
      "height = 43, width = 16586\n",
      "height = 39, width = 16576\n",
      "height = 39, width = 3312\n",
      "height = 35, width = 3299\n",
      "height = 35, width = 3299\n",
      "height = 35, width = 3253\n",
      "height = 18, width = 1623\n",
      "height = 17, width = 1614\n",
      "height = 9, width = 400\n",
      "center_crop=True\n",
      "binaural=False\n",
      "using FIR cochleagram\n",
      "N pitch classes = 8\n",
      "height = 50, width = 100000\n",
      "height = 50, width = 99989\n",
      "height = 50, width = 99989\n",
      "height = 47, width = 99960\n",
      "height = 24, width = 99960\n",
      "height = 21, width = 99885\n",
      "height = 21, width = 49939\n",
      "height = 17, width = 49921\n",
      "height = 9, width = 9981\n",
      "height = 5, width = 9937\n",
      "height = 5, width = 1653\n",
      "height = 4, width = 1614\n",
      "height = 3, width = 400\n",
      "center_crop=True\n",
      "binaural=False\n",
      "using FIR cochleagram\n",
      "N pitch classes = 8\n",
      "height = 50, width = 100000\n",
      "height = 49, width = 99986\n",
      "height = 25, width = 99986\n",
      "height = 22, width = 99953\n",
      "height = 22, width = 24985\n",
      "height = 22, width = 24941\n",
      "height = 12, width = 12467\n",
      "height = 9, width = 12400\n",
      "height = 9, width = 4130\n",
      "height = 6, width = 4101\n",
      "height = 4, width = 2047\n",
      "height = 4, width = 2018\n",
      "height = 3, width = 400\n",
      "center_crop=True\n",
      "binaural=False\n",
      "using FIR cochleagram\n",
      "N pitch classes = 8\n",
      "height = 50, width = 100000\n",
      "height = 50, width = 99941\n",
      "height = 26, width = 33310\n",
      "height = 26, width = 33291\n",
      "height = 14, width = 11094\n",
      "height = 11, width = 11026\n",
      "height = 11, width = 1834\n",
      "height = 11, width = 1796\n",
      "height = 11, width = 895\n",
      "height = 7, width = 859\n",
      "height = 7, width = 859\n",
      "height = 4, width = 807\n",
      "height = 3, width = 400\n",
      "center_crop=True\n",
      "binaural=False\n",
      "using FIR cochleagram\n",
      "N pitch classes = 8\n",
      "height = 50, width = 100000\n",
      "height = 48, width = 99933\n",
      "height = 25, width = 16652\n",
      "height = 22, width = 16616\n",
      "height = 22, width = 16616\n",
      "height = 20, width = 16595\n",
      "height = 20, width = 5528\n",
      "height = 16, width = 5505\n",
      "height = 9, width = 2749\n",
      "height = 8, width = 2737\n",
      "height = 5, width = 1365\n",
      "height = 5, width = 1347\n",
      "height = 3, width = 446\n",
      "height = 2, width = 400\n",
      "height = 2, width = 400\n",
      "center_crop=True\n",
      "binaural=False\n",
      "using FIR cochleagram\n",
      "N pitch classes = 8\n",
      "height = 50, width = 100000\n",
      "height = 49, width = 99945\n",
      "height = 25, width = 33312\n",
      "height = 22, width = 33271\n",
      "height = 22, width = 16632\n",
      "height = 20, width = 16588\n",
      "height = 20, width = 2761\n",
      "height = 17, width = 2699\n",
      "height = 17, width = 2699\n",
      "height = 15, width = 2635\n",
      "height = 8, width = 875\n",
      "height = 7, width = 807\n",
      "height = 7, width = 400\n",
      "center_crop=True\n",
      "binaural=False\n",
      "using FIR cochleagram\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    \n",
    "    config_name = f\"config/arch_search/nsynth_clean_coarse_interval_diff_bins_arch_search_arch_{i}.yaml\"\n",
    "    config = yaml.load(open(config_name, 'r'), Loader=yaml.FullLoader)\n",
    "    module = ModMelModule(config)\n",
    "    del module \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(config_name, 'r'), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'audio': {'compression_kwargs': {'clip_value': 5,\n",
       "    'offset': 1e-07,\n",
       "    'power': 0.3,\n",
       "    'scale': 1},\n",
       "   'compression_type': 'coch_p3',\n",
       "   'rep_kwargs': {'center_crop': True,\n",
       "    'downsampling_kwargs': {'beta': 14.769656459379492,\n",
       "     'lowpass_filter_width': 64,\n",
       "     'resampling_method': 'kaiser_window',\n",
       "     'rolloff': 0.9475937167399596},\n",
       "    'downsampling_type': 'TorchTransformsResample',\n",
       "    'env_extraction_type': 'Half-wave Rectification',\n",
       "    'env_sr': 10000,\n",
       "    'impulse_len': 0.25,\n",
       "    'low_lim': 40,\n",
       "    'n_channels': 50,\n",
       "    'out_dur': 10,\n",
       "    'rep_on_gpu': True,\n",
       "    'sr': 20000,\n",
       "    'use_pad': True},\n",
       "   'rep_type': 'cochlea_filt'},\n",
       "  'bin_kwargs': {'bin_max': 4, 'bin_min': 1, 'n_intervals': 3},\n",
       "  'corpus': {'root': '/om/scratch/Mon/imgriff/datasets/modmel/nsynth_training/',\n",
       "   'with_noise': False},\n",
       "  'loader': {'batch_size': 96, 'num_workers': 10},\n",
       "  'noise_kwargs': {'high_snr': 0, 'low_snr': 0},\n",
       "  'num_class_bins': 8,\n",
       "  'pitch_task': 'coarse_interval'},\n",
       " 'hparas': {'class_weight_path': '/om2/user/imgriff/projects/modmel/nsynth_coarse_class_weights_no_within_note.npy',\n",
       "  'curriculum': 0,\n",
       "  'epochs': 500,\n",
       "  'eps': 1e-08,\n",
       "  'lr': 1e-05,\n",
       "  'lr_scheduler': 'fixed',\n",
       "  'optimizer': 'Adam',\n",
       "  'valid_step': 60},\n",
       " 'model': {'bidirection': False,\n",
       "  'cnn_dim': [32, 64, 128, 256, 512, 512, 512, 512],\n",
       "  'dropout': [0.6],\n",
       "  'kernel': [[3, 42],\n",
       "   [3, 9],\n",
       "   [3, 16],\n",
       "   [1, 17],\n",
       "   [3, 38],\n",
       "   [1, 48],\n",
       "   [3, 5],\n",
       "   [3, 8]],\n",
       "  'layer_norm': [True],\n",
       "  'module': 'GRU',\n",
       "  'padding': [[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]],\n",
       "  'pool_padding': [[0, 0],\n",
       "   [0, 2],\n",
       "   [0, 1],\n",
       "   [1, 0],\n",
       "   [1, 0],\n",
       "   [0, 2],\n",
       "   [1, 3],\n",
       "   [1, 0]],\n",
       "  'pool_size': [[1, 1],\n",
       "   [1, 16],\n",
       "   [1, 8],\n",
       "   [8, 1],\n",
       "   [8, 1],\n",
       "   [1, 16],\n",
       "   [8, 24],\n",
       "   [8, 1]],\n",
       "  'pool_stride': [[1, 1],\n",
       "   [1, 4],\n",
       "   [1, 2],\n",
       "   [2, 1],\n",
       "   [2, 1],\n",
       "   [1, 4],\n",
       "   [2, 6],\n",
       "   [2, 1]],\n",
       "  'proj': [True],\n",
       "  'rnn_dim': [512],\n",
       "  'sample_rate': [1],\n",
       "  'sample_style': 'drop',\n",
       "  'stride': [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]]}}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
